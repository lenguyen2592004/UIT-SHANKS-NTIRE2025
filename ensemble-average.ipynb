{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51ea8b88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T06:57:22.754175Z",
     "iopub.status.busy": "2025-03-22T06:57:22.753972Z",
     "iopub.status.idle": "2025-03-22T06:57:32.399571Z",
     "shell.execute_reply": "2025-03-22T06:57:32.398732Z"
    },
    "papermill": {
     "duration": 9.650581,
     "end_time": "2025-03-22T06:57:32.401196",
     "exception": false,
     "start_time": "2025-03-22T06:57:22.750615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting clip\r\n",
      "  Downloading clip-0.2.0.tar.gz (5.5 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Building wheels for collected packages: clip\r\n",
      "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for clip: filename=clip-0.2.0-py3-none-any.whl size=6988 sha256=7322f7b2d8902740e59b1485b9c639fae4be1bad24e8e67c758de27db0fe14e4\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/7f/5c/e6/2c0fdb453a3569188864b17e9676bea8b3b7e160c037117869\r\n",
      "Successfully built clip\r\n",
      "Installing collected packages: clip\r\n",
      "Successfully installed clip-0.2.0\r\n",
      "Collecting lpips\r\n",
      "  Downloading lpips-0.1.4-py3-none-any.whl.metadata (10 kB)\r\n",
      "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from lpips) (2.5.1+cu121)\r\n",
      "Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from lpips) (0.20.1+cu121)\r\n",
      "Requirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.10/dist-packages (from lpips) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from lpips) (1.13.1)\r\n",
      "Requirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.10/dist-packages (from lpips) (4.67.1)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.3->lpips) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.3->lpips) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.3->lpips) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.3->lpips) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.3->lpips) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.3->lpips) (2.4.1)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (3.17.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (4.12.2)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (2024.12.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=0.4.0->lpips) (1.3.0)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.2.1->lpips) (11.0.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=0.4.0->lpips) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.14.3->lpips) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.14.3->lpips) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.14.3->lpips) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.14.3->lpips) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.14.3->lpips) (2024.2.0)\r\n",
      "Downloading lpips-0.1.4-py3-none-any.whl (53 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: lpips\r\n",
      "Successfully installed lpips-0.1.4\r\n"
     ]
    }
   ],
   "source": [
    "!pip install clip\n",
    "!pip install lpips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cd8ac10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T06:57:32.407975Z",
     "iopub.status.busy": "2025-03-22T06:57:32.407734Z",
     "iopub.status.idle": "2025-03-22T06:57:32.411250Z",
     "shell.execute_reply": "2025-03-22T06:57:32.410642Z"
    },
    "papermill": {
     "duration": 0.007977,
     "end_time": "2025-03-22T06:57:32.412315",
     "exception": false,
     "start_time": "2025-03-22T06:57:32.404338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# from PIL import Image\n",
    "# from skimage.metrics import structural_similarity as ssim, peak_signal_noise_ratio as psnr\n",
    "# from skimage import filters\n",
    "# from skimage.color import rgb2gray\n",
    "# import lpips  # Thư viện LPIPS\n",
    "# #from transformers import CLIPProcessor, CLIPModel\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Định nghĩa thiết bị\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Load mô hình CLIP\n",
    "# #clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
    "# #clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "# # Load LPIPS model\n",
    "# lpips_model = lpips.LPIPS(net='alex').to(device)  # AlexNet là mạng phổ biến cho LPIPS\n",
    "\n",
    "# # Hàm tính PSNR\n",
    "# def compute_psnr(img1, img2):\n",
    "#     return psnr(img1, img2, data_range=img2.max() - img2.min())\n",
    "\n",
    "# # Hàm tính SSIM\n",
    "# def compute_ssim(img1, img2):\n",
    "#     return ssim(img1, img2, data_range=img2.max() - img2.min(), channel_axis=-1)\n",
    "\n",
    "# # Hàm tính LPIPS\n",
    "# def compute_lpips(img1, img2):\n",
    "#     img1_t = torch.from_numpy(img1).permute(2, 0, 1).float().unsqueeze(0).to(device) / 255.0\n",
    "#     img2_t = torch.from_numpy(img2).permute(2, 0, 1).float().unsqueeze(0).to(device) / 255.0\n",
    "#     return lpips_model(img1_t, img2_t).item()\n",
    "\n",
    "# # Hàm tính sắc nét (sharpness)\n",
    "# def compute_sharpness(image):\n",
    "#     return filters.sobel(image).mean()\n",
    "\n",
    "# # Hàm tính độ nét Laplacian\n",
    "# def compute_clarity(image):\n",
    "#     image_gray = cv2.imread(image, cv2.IMREAD_GRAYSCALE)\n",
    "#     return cv2.Laplacian(image_gray, cv2.CV_64F).var()\n",
    "\n",
    "# # Hàm tính độ tương phản\n",
    "# def compute_contrast(image):\n",
    "#     image_gray = cv2.imread(image, cv2.IMREAD_GRAYSCALE)\n",
    "#     return image_gray.std()  # RMS contrast\n",
    "\n",
    "# # Hàm phát hiện giọt nước\n",
    "# def detect_raindrops(image):\n",
    "#     image_gray = cv2.imread(image, cv2.IMREAD_GRAYSCALE)\n",
    "#     _, thresholded = cv2.threshold(image_gray, 200, 255, cv2.THRESH_BINARY)\n",
    "#     raindrop_percentage = np.mean(thresholded) / 255.0\n",
    "#     return raindrop_percentage  # Giá trị càng cao, ảnh có nhiều giọt nước hơn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "492da3e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T06:57:32.418270Z",
     "iopub.status.busy": "2025-03-22T06:57:32.418066Z",
     "iopub.status.idle": "2025-03-22T06:57:32.421657Z",
     "shell.execute_reply": "2025-03-22T06:57:32.421046Z"
    },
    "papermill": {
     "duration": 0.007888,
     "end_time": "2025-03-22T06:57:32.422825",
     "exception": false,
     "start_time": "2025-03-22T06:57:32.414937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# from PIL import Image\n",
    "# from skimage.metrics import structural_similarity as ssim, peak_signal_noise_ratio as psnr\n",
    "# from skimage import filters\n",
    "# import lpips\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# lpips_model = lpips.LPIPS(net='alex').to(device)\n",
    "\n",
    "# def compute_psnr(img1, img2):\n",
    "#     return psnr(img1, img2, data_range=img2.max() - img2.min())\n",
    "\n",
    "# def compute_ssim(img1, img2):\n",
    "#     return ssim(img1, img2, data_range=img2.max() - img2.min(), channel_axis=-1)\n",
    "\n",
    "# def compute_lpips(img1, img2):\n",
    "#     img1_t = torch.from_numpy(img1).permute(2, 0, 1).float().unsqueeze(0).to(device) / 255.0\n",
    "#     img2_t = torch.from_numpy(img2).permute(2, 0, 1).float().unsqueeze(0).to(device) / 255.0\n",
    "#     return lpips_model(img1_t, img2_t).item()\n",
    "\n",
    "# def compute_sharpness(image_gray):\n",
    "#     return filters.sobel(image_gray).mean()\n",
    "\n",
    "# def compute_clarity(image_gray):\n",
    "#     return cv2.Laplacian(image_gray, cv2.CV_64F).var()\n",
    "\n",
    "# def compute_contrast(image_gray):\n",
    "#     return image_gray.std()\n",
    "\n",
    "# def detect_raindrops(image_gray):\n",
    "#     _, thresholded = cv2.threshold(image_gray, 200, 255, cv2.THRESH_BINARY)\n",
    "#     return np.mean(thresholded) / 255.0\n",
    "\n",
    "# def rank_images(folder1, folder2, output_folder):\n",
    "#     os.makedirs(output_folder, exist_ok=True)\n",
    "#     image_names1 = sorted(os.listdir(folder1))\n",
    "#     image_names2 = sorted(os.listdir(folder2))\n",
    "#     image_names = sorted(set(image_names1) & set(image_names2))\n",
    "    \n",
    "#     results = {}\n",
    "#     count_folder1, count_folder2 = 0, 0\n",
    "\n",
    "#     for img_name in image_names:\n",
    "#         img1_path = os.path.join(folder1, img_name)\n",
    "#         img2_path = os.path.join(folder2, img_name)\n",
    "        \n",
    "#         img1 = cv2.imread(img1_path, cv2.IMREAD_COLOR)\n",
    "#         img2 = cv2.imread(img2_path, cv2.IMREAD_COLOR)\n",
    "        \n",
    "#         if img1 is None or img2 is None:\n",
    "#             print(f\"Skipping {img_name} due to read error.\")\n",
    "#             continue\n",
    "        \n",
    "#         img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "#         img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "#         if img1.shape != img2.shape:\n",
    "#             print(f\"Skipping {img_name} due to different dimensions: {img1.shape} vs {img2.shape}.\")\n",
    "#             continue\n",
    "        \n",
    "#         # Convert to grayscale for metrics\n",
    "#         gray1 = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY)\n",
    "#         gray2 = cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "#         psnr_score = compute_psnr(img1, img2)\n",
    "#         ssim_score = compute_ssim(img1, img2)\n",
    "#         lpips_score = compute_lpips(img1, img2)\n",
    "#         score = psnr_score + 10 * ssim_score - 5 * lpips_score\n",
    "\n",
    "#         sharpness1 = compute_sharpness(gray1)\n",
    "#         sharpness2 = compute_sharpness(gray2)\n",
    "#         clarity1 = compute_clarity(gray1)\n",
    "#         clarity2 = compute_clarity(gray2)\n",
    "#         contrast1 = compute_contrast(gray1)\n",
    "#         contrast2 = compute_contrast(gray2)\n",
    "#         raindrop1 = detect_raindrops(gray1)\n",
    "#         raindrop2 = detect_raindrops(gray2)\n",
    "\n",
    "#         score1 = score + (sharpness1 * 0.2) + (contrast1 * 0.2) + (clarity1 * 0.1) - (raindrop1 * 0.5)\n",
    "#         score2 = score + (sharpness2 * 0.2) + (contrast2 * 0.2) + (clarity2 * 0.1) - (raindrop2 * 0.5)\n",
    "\n",
    "#         if score1 > score2:\n",
    "#             best_image = img1_path\n",
    "#             count_folder1 += 1\n",
    "#         else:\n",
    "#             best_image = img2_path\n",
    "#             count_folder2 += 1\n",
    "\n",
    "#         results[img_name] = best_image\n",
    "#         output_path = os.path.join(output_folder, img_name)\n",
    "#         Image.fromarray(img1 if score1 > score2 else img2).save(output_path)\n",
    "\n",
    "#     return results, count_folder1, count_folder2\n",
    "\n",
    "# folder1 = '/kaggle/input/psedo-deblur-30/Clear'\n",
    "# folder2 = '/kaggle/input/patchdm'\n",
    "# output_folder = '.'\n",
    "# selected_images, count_folder1, count_folder2 = rank_images(folder1, folder2, output_folder)\n",
    "\n",
    "# print(f\"Number of selected images from {folder1}: {count_folder1}\")\n",
    "# print(f\"Number of selected images from {folder2}: {count_folder2}\")\n",
    "# selected_list = list(selected_images.values())\n",
    "# print(\"Total selected images:\", len(selected_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "048de16c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T06:57:32.428816Z",
     "iopub.status.busy": "2025-03-22T06:57:32.428583Z",
     "iopub.status.idle": "2025-03-22T06:57:32.432412Z",
     "shell.execute_reply": "2025-03-22T06:57:32.431666Z"
    },
    "papermill": {
     "duration": 0.008047,
     "end_time": "2025-03-22T06:57:32.433558",
     "exception": false,
     "start_time": "2025-03-22T06:57:32.425511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def rank_images(folder1, folder2, output_folder):\n",
    "#     os.makedirs(output_folder, exist_ok=True)\n",
    "#     image_names1 = sorted(os.listdir(folder1))\n",
    "#     image_names2 = sorted(os.listdir(folder2))\n",
    "    \n",
    "#     image_names = sorted(set(image_names1) & set(image_names2))  # Chỉ lấy các ảnh có trong cả hai thư mục\n",
    "#     results = {}\n",
    "#     count_folder1, count_folder2 = 0, 0  # Counters for images selected from each folder\n",
    "    \n",
    "#     for img_name in image_names:\n",
    "#         img1_path = os.path.join(folder1, img_name)\n",
    "#         img2_path = os.path.join(folder2, img_name)\n",
    "        \n",
    "#         # Đọc ảnh RGB\n",
    "#         img1 = cv2.cvtColor(cv2.imread(img1_path), cv2.COLOR_BGR2RGB)\n",
    "#         img2 = cv2.cvtColor(cv2.imread(img2_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#         # Tính toán các chỉ số chất lượng ảnh\n",
    "#         psnr_score = compute_psnr(img1, img2)\n",
    "#         ssim_score = compute_ssim(img1, img2)\n",
    "#         lpips_score = compute_lpips(img1, img2)\n",
    "\n",
    "#         score = psnr_score + 10*ssim_score - 5*lpips_score\n",
    "\n",
    "#         sharpness1, sharpness2 = compute_sharpness(img1), compute_sharpness(img2)\n",
    "#         clarity1, clarity2 = compute_clarity(img1_path), compute_clarity(img2_path)\n",
    "#         contrast1, contrast2 = compute_contrast(img1_path), compute_contrast(img2_path)\n",
    "#         raindrop1, raindrop2 = detect_raindrops(img1_path), detect_raindrops(img2_path)\n",
    "\n",
    "#         # Tính điểm tổng hợp\n",
    "#         score1 = (\n",
    "#             score +\n",
    "#             (sharpness1 * 0.2) + \n",
    "#             (contrast1 * 0.2) +\n",
    "#             (clarity1 * 0.1)-\n",
    "#             (raindrop1 * 0.5)\n",
    "#         )\n",
    "\n",
    "#         score2 = (\n",
    "#             score +\n",
    "#             (sharpness2 * 0.2) + \n",
    "#             (contrast2 * 0.2) +\n",
    "#             (clarity2 * 0.1)-\n",
    "#             (raindrop2 * 0.5)\n",
    "#         )\n",
    "\n",
    "#         # Chọn ảnh có điểm cao hơn\n",
    "#         if score1 > score2:\n",
    "#             best_image = img1_path\n",
    "#             count_folder1 += 1\n",
    "#         else:\n",
    "#             best_image = img2_path\n",
    "#             count_folder2 += 1\n",
    "\n",
    "#         results[img_name] = best_image\n",
    "\n",
    "#         # Lưu ảnh tốt hơn vào thư mục đầu ra\n",
    "#         output_path = os.path.join(output_folder, img_name)\n",
    "#         Image.open(best_image).save(output_path)\n",
    "\n",
    "#     return results, count_folder1, count_folder2\n",
    "\n",
    "\n",
    "# # Sử dụng hàm\n",
    "# folder1 = '/kaggle/input/psedo-deblur-30/Clear'\n",
    "# folder2 = '/kaggle/input/patchdm'\n",
    "# import os\n",
    "# print(\"len folder 1\",len(os.listdir(folder1)))\n",
    "# print(\"len folder 2\",len(os.listdir(folder2)))\n",
    "\n",
    "# output_folder = '.'\n",
    "# selected_images, count_folder1, count_folder2 = rank_images(folder1, folder2, output_folder)\n",
    "\n",
    "# # In kết quả\n",
    "# print(f\"Number of selected images from {folder1}: {count_folder1}\")\n",
    "# print(f\"Number of selected images from {folder2}: {count_folder2}\")\n",
    "\n",
    "# selected_list = list(selected_images.values())\n",
    "# print(\"First 10 selected images:\", selected_list[:10])\n",
    "# print(\"Last 10 selected images:\", selected_list[-10:])\n",
    "# print(\"len of submission folder\",len(selected_images))\n",
    "# for image_path in selected_list[:10] + selected_list[-10:]:\n",
    "#     image = Image.open(image_path)\n",
    "#     plt.figure()\n",
    "#     plt.imshow(image)\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4b6f6ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T06:57:32.439524Z",
     "iopub.status.busy": "2025-03-22T06:57:32.439315Z",
     "iopub.status.idle": "2025-03-22T07:01:05.253818Z",
     "shell.execute_reply": "2025-03-22T07:01:05.252965Z"
    },
    "papermill": {
     "duration": 212.822619,
     "end_time": "2025-03-22T07:01:05.258767",
     "exception": false,
     "start_time": "2025-03-22T06:57:32.436148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
      "100%|██████████| 233M/233M [00:01<00:00, 235MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /usr/local/lib/python3.10/dist-packages/lpips/weights/v0.1/alex.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/lpips/lpips.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.load_state_dict(torch.load(model_path, map_location='cpu'), strict=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected from folder1: 580, folder2: 12\n",
      "Total processed: 592\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from skimage.metrics import structural_similarity as ssim, peak_signal_noise_ratio as psnr\n",
    "from skimage import filters\n",
    "import lpips\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "lpips_model = lpips.LPIPS(net='alex').to(device)\n",
    "\n",
    "def compute_psnr(img1, img2):\n",
    "    return psnr(img1, img2, data_range=img2.max() - img2.min())\n",
    "\n",
    "def compute_ssim(img1, img2):\n",
    "    return ssim(img1, img2, data_range=img2.max() - img2.min(), channel_axis=-1)\n",
    "\n",
    "def compute_lpips(img1, img2):\n",
    "    img1_t = torch.from_numpy(img1).permute(2, 0, 1).float().unsqueeze(0).to(device) / 255.0\n",
    "    img2_t = torch.from_numpy(img2).permute(2, 0, 1).float().unsqueeze(0).to(device) / 255.0\n",
    "    return lpips_model(img1_t, img2_t).item()\n",
    "\n",
    "def compute_sharpness(image_gray):\n",
    "    return filters.sobel(image_gray).mean()\n",
    "\n",
    "def compute_clarity(image_gray):\n",
    "    return cv2.Laplacian(image_gray, cv2.CV_64F).var()\n",
    "\n",
    "def compute_contrast(image_gray):\n",
    "    return image_gray.std()\n",
    "\n",
    "def detect_raindrops(image_gray):\n",
    "    _, thresholded = cv2.threshold(image_gray, 200, 255, cv2.THRESH_BINARY)\n",
    "    return np.mean(thresholded) / 255.0\n",
    "\n",
    "def load_and_resize_image(img_path, target_size=None):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    if img is None:\n",
    "        return None, None\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    if target_size is not None:\n",
    "        img = cv2.resize(img, (target_size[1], target_size[0]), interpolation=cv2.INTER_LINEAR)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    return img, gray\n",
    "\n",
    "def rank_images(folder1, folder2, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    image_names1 = sorted(os.listdir(folder1))\n",
    "    image_names2 = sorted(os.listdir(folder2))\n",
    "    image_names = sorted(set(image_names1) & set(image_names2))\n",
    "    \n",
    "    results = {}\n",
    "    count_folder1, count_folder2 = 0, 0\n",
    "\n",
    "    for img_name in image_names:\n",
    "        img1_path = os.path.join(folder1, img_name)\n",
    "        img2_path = os.path.join(folder2, img_name)\n",
    "        \n",
    "        # Load và resize ảnh từ folder2 theo folder1\n",
    "        img1_rgb, img1_gray = load_and_resize_image(img1_path)\n",
    "        if img1_rgb is None:\n",
    "            print(f\"Skipping {img_name} in folder1 (corrupted)\")\n",
    "            continue\n",
    "            \n",
    "        # Load và resize ảnh từ folder2 theo kích thước của folder1\n",
    "        img2_rgb, img2_gray = load_and_resize_image(img2_path, target_size=img1_rgb.shape[:2])\n",
    "        if img2_rgb is None:\n",
    "            print(f\"Skipping {img_name} in folder2 (corrupted)\")\n",
    "            continue\n",
    "\n",
    "        # Tính toán các chỉ số\n",
    "        psnr_score = compute_psnr(img1_rgb, img2_rgb)\n",
    "        ssim_score = compute_ssim(img1_rgb, img2_rgb)\n",
    "        lpips_score = compute_lpips(img1_rgb, img2_rgb)\n",
    "        base_score = psnr_score + 10*ssim_score - 5*lpips_score\n",
    "\n",
    "        sharpness1 = compute_sharpness(img1_gray)\n",
    "        sharpness2 = compute_sharpness(img2_gray)\n",
    "        clarity1 = compute_clarity(img1_gray)\n",
    "        clarity2 = compute_clarity(img2_gray)\n",
    "        contrast1 = compute_contrast(img1_gray)\n",
    "        contrast2 = compute_contrast(img2_gray)\n",
    "        raindrop1 = detect_raindrops(img1_gray)\n",
    "        raindrop2 = detect_raindrops(img2_gray)\n",
    "\n",
    "        score1 = base_score + (sharpness1 * 0.2) + (contrast1 * 0.2) + (clarity1 * 0.1) - (raindrop1 * 0.5)\n",
    "        score2 = base_score + (sharpness2 * 0.2) + (contrast2 * 0.2) + (clarity2 * 0.1) - (raindrop2 * 0.5)\n",
    "\n",
    "        # Chọn ảnh tốt hơn\n",
    "        if score1 > score2:\n",
    "            best_img = img1_rgb\n",
    "            count_folder1 += 1\n",
    "        else:\n",
    "            best_img = img2_rgb\n",
    "            count_folder2 += 1\n",
    "\n",
    "        # Lưu ảnh kết quả\n",
    "        output_path = os.path.join(output_folder, img_name)\n",
    "        Image.fromarray(best_img).save(output_path)\n",
    "        results[img_name] = output_path\n",
    "\n",
    "    return results, count_folder1, count_folder2\n",
    "\n",
    "# Sử dụng\n",
    "folder1 = '/kaggle/input/psedo-deblur-30/Clear'\n",
    "folder2 = '/kaggle/input/e979w9er'\n",
    "output_folder = '.'\n",
    "selected_images, count1, count2 = rank_images(folder1, folder2, output_folder)\n",
    "\n",
    "print(f\"Selected from folder1: {count1}, folder2: {count2}\")\n",
    "print(\"Total processed:\", len(selected_images))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6740658,
     "sourceId": 10886421,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6616087,
     "sourceId": 11054933,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6932298,
     "sourceId": 11122196,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6936442,
     "sourceId": 11123180,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6936736,
     "sourceId": 11123534,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6936950,
     "sourceId": 11123809,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 227544417,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 228005548,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 228913530,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 228967149,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 228988078,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 226.534309,
   "end_time": "2025-03-22T07:01:06.783344",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-22T06:57:20.249035",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
